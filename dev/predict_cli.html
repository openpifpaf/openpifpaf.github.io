
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Prediction &#8212; OpenPifPaf Guide DEV</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystyle.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="_static/favicon.png"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Examples" href="examples.html" />
    <link rel="prev" title="Introduction" href="intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">OpenPifPaf Guide DEV</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Introduction
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting Started
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Prediction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="examples.html">
   Examples
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapters
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="predict_api.html">
   Prediction API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="compute.html">
   Compute
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="models.html">
   Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="datasets.html">
   Datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="train.html">
   Training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cli_help.html">
   Command Line
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plugins_overview.html">
   Plugins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="faq.html">
   FAQ
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="plugins_custom.html">
   Custom Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plugins_animalpose.html">
   Animal Keypoints
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plugins_wholebody.html">
   WholeBody
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plugins_apollocar3d.html">
   Car Keypoints
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plugins_crowdpose.html">
   CrowdPose
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plugins_nuscenes.html">
   NuScenes 2D detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tutorial_opencv.html">
   OpenCV
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plugins_cifar10.html">
   Cifar10
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="moduledocs.html">
   Modules
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bibliography.html">
   Bibliography
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Development
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="dev.html">
   Contribute
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="performance.html">
   Performance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/openpifpaf/openpifpaf">
   GitHub
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  This is the dev version of the Guide. Here is the <a href="https://openpifpaf.github.io">stable version</a>.
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/predict_cli.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/openpifpaf/openpifpaf"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/openpifpaf/openpifpaf/issues/new?title=Issue%20on%20page%20%2Fpredict_cli.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/openpifpaf/openpifpaf/main?urlpath=tree/guide/predict_cli.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> On this page
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#images">
   Images
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#videos">
   Videos
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#debug">
   Debug
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Prediction</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> On this page </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#images">
   Images
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#videos">
   Videos
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#debug">
   Debug
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="prediction">
<h1>Prediction<a class="headerlink" href="#prediction" title="Permalink to this headline">¶</a></h1>
<p>Use the <a class="reference internal" href="cli_help.html#cli-help-predict"><span class="std std-ref">openpifpaf.predict</span></a> tool on the command line to run
multi-person pose estimation on images.
To create predictions from other Python modules, please refer to <a class="reference internal" href="predict_api.html"><span class="doc">Prediction API</span></a>.
First we present the command line tool for predictions on images,
<a class="reference internal" href="cli_help.html#cli-help-predict"><span class="std std-ref">openpifpaf.predict</span></a>. Then follows
a short introduction to OpenPifPaf predictions on videos with
<a class="reference internal" href="cli_help.html#cli-help-video"><span class="std std-ref">openpifpaf.video</span></a>.</p>
<div class="section" id="images">
<h2>Images<a class="headerlink" href="#images" title="Permalink to this headline">¶</a></h2>
<p>Run <a class="reference internal" href="cli_help.html#cli-help-predict"><span class="std std-ref">openpifpaf.predict</span></a> on an image:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
python -m openpifpaf.predict coco/000000081988.jpg --image-output --json-output
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:__main__:neural network device: cpu (CUDA available: False, count: 0)
INFO:openpifpaf.decoder.factory:No specific decoder requested. Using the first one from:
  --decoder=cifcaf:0
  --decoder=posesimilarity:0
Use any of the above arguments to select one or multiple decoders and to suppress this message.
INFO:openpifpaf.predictor:neural network device: cpu (CUDA available: False, count: 0)
INFO:openpifpaf.decoder.cifcaf:annotations 5: [16, 14, 13, 12, 12]
INFO:openpifpaf.predictor:batch 0: coco/000000081988.jpg
/home/runner/work/openpifpaf/openpifpaf/src/openpifpaf/csrc/src/cif_hr.cpp:102: UserInfo: resizing cifhr buffer
/home/runner/work/openpifpaf/openpifpaf/src/openpifpaf/csrc/src/occupancy.cpp:53: UserInfo: resizing occupancy buffer
</pre></div>
</div>
</div>
</div>
<p>This command produced two outputs: an image and a json file.
You can provide file or folder arguments to the <code class="docutils literal notranslate"><span class="pre">--image-output</span></code> and <code class="docutils literal notranslate"><span class="pre">--json-output</span></code> flags.
Here, we used the default which created these two files:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>coco/000000081988.jpg.predictions.jpeg
coco/000000081988.jpg.predictions.json
</pre></div>
</div>
<p>Here is the image:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">IPython</span>
<span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="s1">&#39;coco/000000081988.jpg.predictions.jpeg&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/predict_cli_3_0.jpg" src="_images/predict_cli_3_0.jpg" />
</div>
</div>
<p>Image credit: “<a class="reference external" href="https://www.flickr.com/photos/fotologic/6038911779/in/photostream/">Learning to surf</a>” by fotologic which is licensed under <a class="reference external" href="https://creativecommons.org/licenses/by/2.0/">CC-BY-2.0</a>.</p>
<p>And below is the json output. The json data is a list where each entry in the list corresponds to one pose annotation. In this case, there are five entries corresponding to the five people in the image. Each annotation contains information on <code class="docutils literal notranslate"><span class="pre">&quot;keypoints&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;bbox&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;score&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;category_id&quot;</span></code>.</p>
<p>All coordinates are in pixel coordinates. The <code class="docutils literal notranslate"><span class="pre">&quot;keypoints&quot;</span></code> entry is in COCO format with triples of <code class="docutils literal notranslate"><span class="pre">(x,</span> <span class="pre">y,</span> <span class="pre">c)</span></code> (<code class="docutils literal notranslate"><span class="pre">c</span></code> for confidence) for every joint as listed under <a class="reference internal" href="datasets.html#coco-person-keypoints"><span class="std std-ref">COCO Person Keypoints</span></a>. The pixel coordinates have sub-pixel accuracy, i.e. 10.5 means the joint is between pixel 10 and 11.
In rare cases, joints can be localized outside the field of view and then the pixel coordinates can be negative. When <code class="docutils literal notranslate"><span class="pre">c</span></code> is zero, the joint was not detected.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">&quot;bbox&quot;</span></code> (bounding box) format is <code class="docutils literal notranslate"><span class="pre">(x,</span> <span class="pre">y,</span> <span class="pre">w,</span> <span class="pre">h)</span></code>: the <span class="math notranslate nohighlight">\((x, y)\)</span> coordinate of the top-left corner followed by width and height.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">&quot;score&quot;</span></code> is a number between zero and one.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
python -m json.tool coco/000000081988.jpg.predictions.json
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[
    {
        &quot;keypoints&quot;: [
            360.18,
            299.65,
            1.0,
            364.04,
            294.79,
            0.96,
            355.07,
            295.04,
            0.98,
            369.58,
            297.13,
            0.83,
            347.77,
            298.04,
            0.94,
            381.79,
            317.4,
            0.94,
            341.23,
            321.81,
            0.95,
            387.61,
            341.62,
            0.62,
            335.08,
            350.91,
            0.96,
            373.34,
            356.88,
            0.44,
            335.82,
            363.87,
            0.9,
            373.8,
            362.83,
            0.86,
            350.46,
            364.86,
            0.96,
            388.86,
            361.72,
            0.66,
            328.08,
            374.7,
            0.69,
            338.47,
            381.58,
            0.34,
            0.0,
            -3.0,
            0.0
        ],
        &quot;bbox&quot;: [
            321.09,
            292.01,
            74.9,
            96.17
        ],
        &quot;score&quot;: 0.821,
        &quot;category_id&quot;: 1
    },
    {
        &quot;keypoints&quot;: [
            81.04,
            316.39,
            0.8,
            84.85,
            313.13,
            0.88,
            79.19,
            312.31,
            0.67,
            99.87,
            308.71,
            0.96,
            0.0,
            -3.0,
            0.0,
            121.95,
            317.08,
            1.0,
            78.87,
            322.75,
            0.98,
            145.26,
            347.63,
            0.99,
            59.34,
            349.75,
            0.96,
            125.94,
            353.11,
            0.96,
            52.33,
            381.5,
            0.97,
            121.69,
            359.37,
            0.97,
            95.56,
            363.15,
            0.97,
            152.58,
            360.37,
            0.91,
            72.03,
            367.25,
            0.88,
            0.0,
            -3.0,
            0.0,
            0.0,
            -3.0,
            0.0
        ],
        &quot;bbox&quot;: [
            45.13,
            305.11,
            116.65,
            83.59
        ],
        &quot;score&quot;: 0.819,
        &quot;category_id&quot;: 1
    },
    {
        &quot;keypoints&quot;: [
            0.0,
            -3.0,
            0.0,
            0.0,
            -3.0,
            0.0,
            0.0,
            -3.0,
            0.0,
            388.01,
            149.0,
            1.0,
            410.68,
            149.9,
            0.95,
            376.6,
            177.27,
            0.98,
            425.45,
            178.19,
            0.98,
            337.24,
            190.82,
            0.98,
            463.56,
            192.09,
            0.98,
            301.44,
            193.76,
            0.98,
            495.15,
            185.29,
            0.97,
            389.34,
            251.83,
            0.97,
            414.38,
            251.49,
            0.98,
            384.25,
            315.64,
            0.82,
            409.22,
            317.9,
            0.96,
            0.0,
            -3.0,
            0.0,
            405.56,
            367.51,
            0.66
        ],
        &quot;bbox&quot;: [
            289.84,
            142.48,
            216.49,
            234.07
        ],
        &quot;score&quot;: 0.788,
        &quot;category_id&quot;: 1
    },
    {
        &quot;keypoints&quot;: [
            239.69,
            318.88,
            0.48,
            0.0,
            -3.0,
            0.0,
            235.94,
            316.98,
            0.68,
            0.0,
            -3.0,
            0.0,
            222.3,
            314.72,
            0.84,
            241.28,
            320.26,
            0.93,
            201.98,
            316.96,
            1.0,
            241.98,
            351.26,
            0.83,
            197.04,
            349.91,
            0.78,
            240.17,
            378.14,
            0.77,
            195.31,
            375.14,
            0.67,
            222.78,
            339.59,
            0.61,
            199.07,
            340.1,
            0.58,
            222.55,
            374.28,
            0.42,
            0.0,
            -3.0,
            0.0,
            0.0,
            -3.0,
            0.0,
            0.0,
            -3.0,
            0.0
        ],
        &quot;bbox&quot;: [
            190.44,
            312.1,
            56.65,
            70.61
        ],
        &quot;score&quot;: 0.614,
        &quot;category_id&quot;: 1
    },
    {
        &quot;keypoints&quot;: [
            493.12,
            349.29,
            0.61,
            494.84,
            345.06,
            0.55,
            488.95,
            346.07,
            0.53,
            503.2,
            333.74,
            0.44,
            0.0,
            -3.0,
            0.0,
            522.08,
            331.19,
            0.76,
            492.33,
            334.51,
            0.55,
            549.21,
            351.31,
            0.65,
            0.0,
            -3.0,
            0.0,
            0.0,
            -3.0,
            0.0,
            0.0,
            -3.0,
            0.0,
            542.72,
            344.51,
            0.86,
            523.54,
            346.43,
            1.0,
            522.31,
            377.06,
            0.81,
            501.11,
            378.52,
            0.88,
            566.24,
            384.99,
            0.62,
            0.0,
            -3.0,
            0.0
        ],
        &quot;bbox&quot;: [
            486.3,
            325.06,
            87.45,
            67.44
        ],
        &quot;score&quot;: 0.597,
        &quot;category_id&quot;: 1
    }
]
</pre></div>
</div>
</div>
</div>
<p>Optional Arguments:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--show</span></code>: show interactive matplotlib output</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--debug-indices</span></code>: enable debug messages and debug plots (see <a class="reference internal" href="examples.html#example-debug"><span class="std std-ref">Examples</span></a>)</p></li>
</ul>
<p>Full list of arguments is available with <code class="docutils literal notranslate"><span class="pre">--help</span></code>: <a class="reference internal" href="cli_help.html#cli-help-predict"><span class="std std-ref">CLI help for predict</span></a>.</p>
</div>
<div class="section" id="videos">
<h2>Videos<a class="headerlink" href="#videos" title="Permalink to this headline">¶</a></h2>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>python3 -m openpifpaf.video --source myvideotoprocess.mp4 --video-output --json-output
</pre></div>
</div>
<p>Requires OpenCV. The <code class="docutils literal notranslate"><span class="pre">--video-output</span></code> option also requires matplotlib.
Replace <code class="docutils literal notranslate"><span class="pre">myvideotoprocess.mp4</span></code> with <code class="docutils literal notranslate"><span class="pre">0</span></code> for webcam0 or other OpenCV compatible sources.
The full list of arguments is available with <code class="docutils literal notranslate"><span class="pre">--help</span></code>: <a class="reference internal" href="cli_help.html#cli-help-video"><span class="std std-ref">CLI help for video</span></a>.</p>
<p>In v0.12.6, we introduced the ability to pipe the output to a virtual camera.
This virtual camera can then be used as the source camera in Zoom and other
conferencing softwares. You need a virtual camera on your system, e.g.
from <a class="reference external" href="https://obsproject.com">OBS Studio</a> (Mac and Windows) or
<a class="reference external" href="https://github.com/umlaeute/v4l2loopback#distributions">v4l2loopback</a> (Linux)
and need to install <code class="docutils literal notranslate"><span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">pyvirtualcam</span></code>. Then you can use the
<code class="docutils literal notranslate"><span class="pre">--video-output=virtualcam</span></code> argument.</p>
</div>
<div class="section" id="debug">
<h2>Debug<a class="headerlink" href="#debug" title="Permalink to this headline">¶</a></h2>
<p>Obtain extra information by adding <code class="docutils literal notranslate"><span class="pre">--debug</span></code> to the command line. It will
show the structure of the neural network and timing information in the decoder.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
python -m openpifpaf.predict coco/000000081988.jpg --image-output --json-output --debug
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:__main__:neural network device: cpu (CUDA available: False, count: 0)
DEBUG:openpifpaf.show.painters:color connections = False, lw = 6, marker = 3
DEBUG:openpifpaf.network.factory:Shell(
  (base_net): ShuffleNetV2K(
    (input_block): Sequential(
      (0): Sequential(
        (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (stage2): Sequential(
      (0): InvertedResidualK(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Conv2d(24, 174, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(174, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 174, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(174, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(174, 174, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=174, bias=False)
          (4): BatchNorm2d(174, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): Conv2d(174, 174, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(174, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidualK(
        (branch2): Sequential(
          (0): Conv2d(174, 174, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(174, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(174, 174, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=174, bias=False)
          (4): BatchNorm2d(174, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): Conv2d(174, 174, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(174, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidualK(
        (branch2): Sequential(
          (0): Conv2d(174, 174, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(174, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(174, 174, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=174, bias=False)
          (4): BatchNorm2d(174, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): Conv2d(174, 174, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(174, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidualK(
        (branch2): Sequential(
          (0): Conv2d(174, 174, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(174, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(174, 174, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=174, bias=False)
          (4): BatchNorm2d(174, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): Conv2d(174, 174, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(174, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidualK(
        (branch1): Sequential(
          (0): Conv2d(348, 348, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=348, bias=False)
          (1): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Conv2d(348, 348, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(348, 348, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(348, 348, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=348, bias=False)
          (4): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): Conv2d(348, 348, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidualK(
        (branch2): Sequential(
          (0): Conv2d(348, 348, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(348, 348, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=348, bias=False)
          (4): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): Conv2d(348, 348, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidualK(
        (branch2): Sequential(
          (0): Conv2d(348, 348, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(348, 348, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=348, bias=False)
          (4): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): Conv2d(348, 348, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidualK(
        (branch2): Sequential(
          (0): Conv2d(348, 348, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(348, 348, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=348, bias=False)
          (4): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): Conv2d(348, 348, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidualK(
        (branch2): Sequential(
          (0): Conv2d(348, 348, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(348, 348, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=348, bias=False)
          (4): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): Conv2d(348, 348, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidualK(
        (branch2): Sequential(
          (0): Conv2d(348, 348, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(348, 348, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=348, bias=False)
          (4): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): Conv2d(348, 348, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidualK(
        (branch2): Sequential(
          (0): Conv2d(348, 348, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(348, 348, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=348, bias=False)
          (4): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): Conv2d(348, 348, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidualK(
        (branch2): Sequential(
          (0): Conv2d(348, 348, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(348, 348, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=348, bias=False)
          (4): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): Conv2d(348, 348, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(348, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidualK(
        (branch1): Sequential(
          (0): Conv2d(696, 696, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=696, bias=False)
          (1): BatchNorm2d(696, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Conv2d(696, 696, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(696, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(696, 696, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(696, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(696, 696, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=696, bias=False)
          (4): BatchNorm2d(696, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): Conv2d(696, 696, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(696, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidualK(
        (branch2): Sequential(
          (0): Conv2d(696, 696, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(696, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(696, 696, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=696, bias=False)
          (4): BatchNorm2d(696, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): Conv2d(696, 696, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(696, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidualK(
        (branch2): Sequential(
          (0): Conv2d(696, 696, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(696, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(696, 696, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=696, bias=False)
          (4): BatchNorm2d(696, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): Conv2d(696, 696, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(696, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidualK(
        (branch2): Sequential(
          (0): Conv2d(696, 696, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(696, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(696, 696, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=696, bias=False)
          (4): BatchNorm2d(696, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): Conv2d(696, 696, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(696, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(1392, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(1392, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (head_nets): ModuleList(
    (0): CompositeField4(
      (dropout): Dropout2d(p=0.0, inplace=False)
      (conv): Conv2d(1392, 340, kernel_size=(1, 1), stride=(1, 1))
      (upsample_op): PixelShuffle(upscale_factor=2)
    )
    (1): CompositeField4(
      (dropout): Dropout2d(p=0.0, inplace=False)
      (conv): Conv2d(1392, 608, kernel_size=(1, 1), stride=(1, 1))
      (upsample_op): PixelShuffle(upscale_factor=2)
    )
  )
)
DEBUG:openpifpaf.decoder.factory:head names = [&#39;cif&#39;, &#39;caf&#39;]
DEBUG:openpifpaf.signal:subscribe to eval_reset
DEBUG:openpifpaf.decoder.pose_similarity:valid keypoints = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
DEBUG:openpifpaf.visualizer.base:cif: indices = []
DEBUG:openpifpaf.show.painters:color connections = True, lw = 2, marker = 6
DEBUG:openpifpaf.show.painters:color connections = False, lw = 6, marker = 3
DEBUG:openpifpaf.visualizer.base:cif: indices = []
DEBUG:openpifpaf.visualizer.base:caf: indices = []
DEBUG:openpifpaf.show.painters:color connections = True, lw = 2, marker = 6
DEBUG:openpifpaf.show.painters:color connections = False, lw = 6, marker = 3
DEBUG:openpifpaf.visualizer.base:cif: indices = []
DEBUG:openpifpaf.show.painters:color connections = True, lw = 2, marker = 6
DEBUG:openpifpaf.show.painters:color connections = False, lw = 6, marker = 3
DEBUG:openpifpaf.visualizer.base:cif: indices = []
DEBUG:openpifpaf.visualizer.base:caf: indices = []
DEBUG:openpifpaf.show.painters:color connections = True, lw = 2, marker = 6
DEBUG:openpifpaf.show.painters:color connections = False, lw = 6, marker = 3
DEBUG:openpifpaf.decoder.factory:created 2 decoders
INFO:openpifpaf.decoder.factory:No specific decoder requested. Using the first one from:
  --decoder=cifcaf:0
  --decoder=posesimilarity:0
Use any of the above arguments to select one or multiple decoders and to suppress this message.
INFO:openpifpaf.predictor:neural network device: cpu (CUDA available: False, count: 0)
DEBUG:openpifpaf.transforms.pad:valid area before pad: [  0.   0. 639. 426.], image size = (640, 427)
DEBUG:openpifpaf.transforms.pad:pad with (0, 3, 1, 3)
DEBUG:openpifpaf.transforms.pad:valid area after pad: [  0.   3. 639. 426.], image size = (641, 433)
DEBUG:openpifpaf.decoder.decoder:nn processing time: 824.9ms
DEBUG:openpifpaf.decoder.decoder:parallel execution with worker &lt;openpifpaf.decoder.decoder.DummyPool object at 0x7f93e2f7eca0&gt;
DEBUG:openpifpaf.decoder.multi:task 0
DEBUG:openpifpaf.decoder.cifcaf:cpp annotations = 5 (14.4ms)
INFO:openpifpaf.decoder.cifcaf:annotations 5: [16, 14, 13, 12, 12]
DEBUG:openpifpaf.decoder.decoder:time: nn = 825.2ms, dec = 15.7ms
INFO:openpifpaf.predictor:batch 0: coco/000000081988.jpg
DEBUG:__main__:json output = coco/000000081988.jpg.predictions.json
DEBUG:__main__:image output = coco/000000081988.jpg.predictions.jpeg
DEBUG:openpifpaf.show.canvas:writing image to coco/000000081988.jpg.predictions.jpeg
/home/runner/work/openpifpaf/openpifpaf/src/openpifpaf/csrc/src/cif_hr.cpp:102: UserInfo: resizing cifhr buffer
/home/runner/work/openpifpaf/openpifpaf/src/openpifpaf/csrc/src/occupancy.cpp:53: UserInfo: resizing occupancy buffer
</pre></div>
</div>
</div>
</div>
<p>You can enable debug plots with <code class="docutils literal notranslate"><span class="pre">--debug-indices</span></code>.
Please refer to <a class="reference internal" href="examples.html#example-debug"><span class="std std-ref">the debug outputs in the Examples</span></a> and
some further <a class="reference internal" href="predict_api.html#predict-fields"><span class="std std-ref">debug outputs in the prediction API</span></a>.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Introduction</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="examples.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Examples</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By <a href="https://www.svenkreiss.com">Sven Kreiss</a> and <a href="https://github.com/openpifpaf/openpifpaf/graphs/contributors">contributors</a>.<br/>
    
        &copy; Copyright 2020-2021.<br/>
      <div class="extra_footer">
        <p>Powered by <a href="https://jupyterbook.org/">Jupyter Book</a>.</p>

      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>